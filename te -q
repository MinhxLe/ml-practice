Help on module torch.distributions.multivariate_normal in torch.distributions:

NNAAMMEE
    torch.distributions.multivariate_normal - # mypy: allow-untyped-defs

CCLLAASSSSEESS
    torch.distributions.distribution.Distribution(builtins.object)
        MultivariateNormal
    
    class MMuullttiivvaarriiaatteeNNoorrmmaall(torch.distributions.distribution.Distribution)
     |  MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
     |  
     |  Creates a multivariate normal (also called Gaussian) distribution
     |  parameterized by a mean vector and a covariance matrix.
     |  
     |  The multivariate normal distribution can be parameterized either
     |  in terms of a positive definite covariance matrix :math:`\mathbf{\Sigma}`
     |  or a positive definite precision matrix :math:`\mathbf{\Sigma}^{-1}`
     |  or a lower-triangular matrix :math:`\mathbf{L}` with positive-valued
     |  diagonal entries, such that
     |  :math:`\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top`. This triangular matrix
     |  can be obtained via e.g. Cholesky decomposition of the covariance.
     |  
     |  Example:
     |  
     |      >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)
     |      >>> # xdoctest: +IGNORE_WANT("non-deterministic")
     |      >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))
     |      >>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`
     |      tensor([-0.2102, -0.5429])
     |  
     |  Args:
     |      loc (Tensor): mean of the distribution
     |      covariance_matrix (Tensor): positive-definite covariance matrix
     |      precision_matrix (Tensor): positive-definite precision matrix
     |      scale_tril (Tensor): lower-triangular factor of covariance, with positive-valued diagonal
     |  
     |  Note:
     |      Only one of :attr:`covariance_matrix` or :attr:`precision_matrix` or
     |      :attr:`scale_tril` can be specified.
     |  
     |      Using :attr:`scale_tril` will be more efficient: all computations internally
     |      are based on :attr:`scale_tril`. If :attr:`covariance_matrix` or
     |      :attr:`precision_matrix` is passed instead, it is only used to compute
     |      the corresponding lower triangular matrices using a Cholesky decomposition.
     |  
     |  Method resolution order:
     |      MultivariateNormal
     |      torch.distributions.distribution.Distribution
     |      builtins.object
     |  
     |  Methods defined here:
     |  
     |  ____iinniitt____(self, loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |  
     |  eennttrrooppyy(self)
     |      Returns entropy of distribution, batched over batch_shape.
     |      
     |      Returns:
     |          Tensor of shape batch_shape.
     |  
     |  eexxppaanndd(self, batch_shape, _instance=None)
     |      Returns a new distribution instance (or populates an existing instance
     |      provided by a derived class) with batch dimensions expanded to
     |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on
     |      the distribution's parameters. As such, this does not allocate new
     |      memory for the expanded distribution instance. Additionally,
     |      this does not repeat any args checking or parameter broadcasting in
     |      `__init__.py`, when an instance is first created.
     |      
     |      Args:
     |          batch_shape (torch.Size): the desired expanded size.
     |          _instance: new instance provided by subclasses that
     |              need to override `.expand`.
     |      
     |      Returns:
     |          New distribution instance with batch dimensions expanded to
     |          `batch_size`.
     |  
     |  lloogg__pprroobb(self, value)
     |      Returns the log of the probability density/mass function evaluated at
     |      `value`.
     |      
     |      Args:
     |          value (Tensor):
     |  
     |  rrssaammppllee(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor
     |      Generates a sample_shape shaped reparameterized sample or sample_shape
     |      shaped batch of reparameterized samples if the distribution parameters
     |      are batched.
     |  
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |  
     |  ccoovvaarriiaannccee__mmaattrriixx
     |  
     |  mmeeaann
     |      Returns the mean of the distribution.
     |  
     |  mmooddee
     |      Returns the mode of the distribution.
     |  
     |  pprreecciissiioonn__mmaattrriixx
     |  
     |  ssccaallee__ttrriill
     |  
     |  vvaarriiaannccee
     |      Returns the variance of the distribution.
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |  
     |  aarrgg__ccoonnssttrraaiinnttss = {'covariance_matrix': PositiveDefinite(), 'loc': Ind...
     |  
     |  hhaass__rrssaammppllee = True
     |  
     |  ssuuppppoorrtt = IndependentConstraint(Real(), 1)
     |  
     |  ----------------------------------------------------------------------
     |  Methods inherited from torch.distributions.distribution.Distribution:
     |  
     |  ____rreepprr____(self) -> str
     |      Return repr(self).
     |  
     |  ccddff(self, value: torch.Tensor) -> torch.Tensor
     |      Returns the cumulative density/mass function evaluated at
     |      `value`.
     |      
     |      Args:
     |          value (Tensor):
     |  
     |  eennuummeerraattee__ssuuppppoorrtt(self, expand: bool = True) -> torch.Tensor
     |      Returns tensor containing all values supported by a discrete
     |      distribution. The result will enumerate over dimension 0, so the shape
     |      of the result will be `(cardinality,) + batch_shape + event_shape`
     |      (where `event_shape = ()` for univariate distributions).
     |      
     |      Note that this enumerates over all batched tensors in lock-step
     |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens
     |      along dim 0, but with the remaining batch dimensions being
     |      singleton dimensions, `[[0], [1], ..`.
     |      
     |      To iterate over the full Cartesian product use
     |      `itertools.product(m.enumerate_support())`.
     |      
     |      Args:
     |          expand (bool): whether to expand the support over the
     |              batch dims to match the distribution's `batch_shape`.
     |      
     |      Returns:
     |          Tensor iterating over dimension 0.
     |  
     |  iiccddff(self, value: torch.Tensor) -> torch.Tensor
     |      Returns the inverse cumulative density/mass function evaluated at
     |      `value`.
     |      
     |      Args:
     |          value (Tensor):
     |  
     |  ppeerrpplleexxiittyy(self) -> torch.Tensor
     |      Returns perplexity of distribution, batched over batch_shape.
     |      
     |      Returns:
     |          Tensor of shape batch_shape.
     |  
     |  ssaammppllee(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor
     |      Generates a sample_shape shaped sample or sample_shape shaped batch of
     |      samples if the distribution parameters are batched.
     |  
     |  ssaammppllee__nn(self, n: int) -> torch.Tensor
     |      Generates n samples or n batches of samples if the distribution
     |      parameters are batched.
     |  
     |  ----------------------------------------------------------------------
     |  Static methods inherited from torch.distributions.distribution.Distribution:
     |  
     |  sseett__ddeeffaauulltt__vvaalliiddaattee__aarrggss(value: bool) -> None
     |      Sets whether validation is enabled or disabled.
     |      
     |      The default behavior mimics Python's ``assert`` statement: validation
     |      is on by default, but is disabled if Python is run in optimized mode
     |      (via ``python -O``). Validation may be expensive, so you may want to
     |      disable it once a model is working.
     |      
     |      Args:
     |          value (bool): Whether to enable validation.
     |  
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from torch.distributions.distribution.Distribution:
     |  
     |  bbaattcchh__sshhaappee
     |      Returns the shape over which parameters are batched.
     |  
     |  eevveenntt__sshhaappee
     |      Returns the shape of a single sample (without batching).
     |  
     |  ssttddddeevv
     |      Returns the standard deviation of the distribution.
     |  
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from torch.distributions.distribution.Distribution:
     |  
     |  ____ddiicctt____
     |      dictionary for instance variables
     |  
     |  ____wweeaakkrreeff____
     |      list of weak references to the object
     |  
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from torch.distributions.distribution.Distribution:
     |  
     |  hhaass__eennuummeerraattee__ssuuppppoorrtt = False

DDAATTAA
    ____aallll____ = ['MultivariateNormal']

FFIILLEE
    /home/minh/career/interview_prep/ml-practice/.venv/lib/python3.11/site-packages/torch/distributions/multivariate_normal.py

Help on built-in function view:

vviieeww(...) method of torch.Tensor instance
    view(*shape) -> Tensor
    
    Returns a new tensor with the same data as the :attr:`self` tensor but of a
    different :attr:`shape`.
    
    The returned tensor shares the same data and must have the same number
    of elements, but may have a different size. For a tensor to be viewed, the new
    view size must be compatible with its original size and stride, i.e., each new
    view dimension must either be a subspace of an original dimension, or only span
    across original dimensions :math:`d, d+1, \dots, d+k` that satisfy the following
    contiguity-like condition that :math:`\forall i = d, \dots, d+k-1`,
    
    .. math::
    
      \text{stride}[i] = \text{stride}[i+1] \times \text{size}[i+1]
    
    Otherwise, it will not be possible to view :attr:`self` tensor as :attr:`shape`
    without copying it (e.g., via :meth:`contiguous`). When it is unclear whether a
    :meth:`view` can be performed, it is advisable to use :meth:`reshape`, which
    returns a view if the shapes are compatible, and copies (equivalent to calling
    :meth:`contiguous`) otherwise.
    
    Args:
        shape (torch.Size or int...): the desired size
    
    Example::
    
        >>> x = torch.randn(4, 4)
        >>> x.size()
        torch.Size([4, 4])
        >>> y = x.view(16)
        >>> y.size()
        torch.Size([16])
        >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions
        >>> z.size()
        torch.Size([2, 8])
    
        >>> a = torch.randn(1, 2, 3, 4)
        >>> a.size()
        torch.Size([1, 2, 3, 4])
        >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension
        >>> b.size()
        torch.Size([1, 3, 2, 4])
        >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory
        >>> c.size()
        torch.Size([1, 3, 2, 4])
        >>> torch.equal(b, c)
        False
    
    
    .. method:: view(dtype) -> Tensor
       :noindex:
    
    Returns a new tensor with the same data as the :attr:`self` tensor but of a
    different :attr:`dtype`.
    
    If the element size of :attr:`dtype` is different than that of ``self.dtype``,
    then the size of the last dimension of the output will be scaled
    proportionally.  For instance, if :attr:`dtype` element size is twice that of
    ``self.dtype``, then each pair of elements in the last dimension of
    :attr:`self` will be combined, and the size of the last dimension of the output
    will be half that of :attr:`self`. If :attr:`dtype` element size is half that
    of ``self.dtype``, then each element in the last dimension of :attr:`self` will
    be split in two, and the size of the last dimension of the output will be
    double that of :attr:`self`. For this to be possible, the following conditions
    must be true:
    
        * ``self.dim()`` must be greater than 0.
        * ``self.stride(-1)`` must be 1.
    
    Additionally, if the element size of :attr:`dtype` is greater than that of
    ``self.dtype``, the following conditions must be true as well:
    
        * ``self.size(-1)`` must be divisible by the ratio between the element
          sizes of the dtypes.
        * ``self.storage_offset()`` must be divisible by the ratio between the
          element sizes of the dtypes.
        * The strides of all dimensions, except the last dimension, must be
          divisible by the ratio between the element sizes of the dtypes.
    
    If any of the above conditions are not met, an error is thrown.
    
    .. warning::
    
        This overload is not supported by TorchScript, and using it in a Torchscript
        program will cause undefined behavior.
    
    
    Args:
        dtype (:class:`torch.dtype`): the desired dtype
    
    Example::
    
        >>> x = torch.randn(4, 4)
        >>> x
        tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],
                [-0.1520,  0.7472,  0.5617, -0.8649],
                [-2.4724, -0.0334, -0.2976, -0.8499],
                [-0.2109,  1.9913, -0.9607, -0.6123]])
        >>> x.dtype
        torch.float32
    
        >>> y = x.view(torch.int32)
        >>> y
        tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],
                [-1105482831,  1061112040,  1057999968, -1084397505],
                [-1071760287, -1123489973, -1097310419, -1084649136],
                [-1101533110,  1073668768, -1082790149, -1088634448]],
            dtype=torch.int32)
        >>> y[0, 0] = 1000000000
        >>> x
        tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],
                [-0.1520,  0.7472,  0.5617, -0.8649],
                [-2.4724, -0.0334, -0.2976, -0.8499],
                [-0.2109,  1.9913, -0.9607, -0.6123]])
    
        >>> x.view(torch.cfloat)
        tensor([[ 0.0047-0.0310j,  1.4999-0.5316j],
                [-0.1520+0.7472j,  0.5617-0.8649j],
                [-2.4724-0.0334j, -0.2976-0.8499j],
                [-0.2109+1.9913j, -0.9607-0.6123j]])
        >>> x.view(torch.cfloat).size()
        torch.Size([4, 2])
    
        >>> x.view(torch.uint8)
        tensor([[  0, 202, 154,  59, 182, 243, 253, 188, 185, 252, 191,  63, 240,  22,
                   8, 191],
                [227, 165,  27, 190, 128,  72,  63,  63, 146, 203,  15,  63,  22, 106,
                  93, 191],
                [205,  59,  30, 192, 112, 206,   8, 189,   7,  95, 152, 190,  12, 147,
                  89, 191],
                [ 43, 246,  87, 190, 235, 226, 254,  63, 111, 240, 117, 191, 177, 191,
                  28, 191]], dtype=torch.uint8)
        >>> x.view(torch.uint8).size()
        torch.Size([4, 16])
